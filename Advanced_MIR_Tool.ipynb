{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced-MIR-Tool.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOqqgbCuLcjYe0nrVJc+r4e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/Tegridy-MIDI-Dataset/blob/master/Advanced_MIR_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aAiHnVH9CQH"
      },
      "source": [
        "# Advanced MIR Tool (Ver. 1.2.)\n",
        "\n",
        "***\n",
        "\n",
        "## Based on a work of love by Willie Payne and Ana Elisa Mendez Mendez, on whose repo and code it is based: https://github.com/Huriphoonado\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2020\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOADCl850DqJ",
        "cellView": "form"
      },
      "source": [
        "#@title Install Dependencies\n",
        "#!pip install ipython -U\n",
        "#!pip install ipython_genutils -U\n",
        "!git clone https://github.com/marl/medleydb.git\n",
        "%cd /content/medleydb\n",
        "!python setup.py install\n",
        "!sudo apt-get install sox libsox-fmt-mp3\n",
        "!pip install pyyaml\n",
        "!!pip install numpy\n",
        "!pip install six\n",
        "!pip install librosa\n",
        "!pip install pydrive\n",
        "!pip install scipy\n",
        "!pip install scikit-learn\n",
        "\n",
        "!pip install mir-eval\n",
        "!pip install pretty_midi\n",
        "!pip install pypianoroll\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0nYs6ag1NSZ",
        "cellView": "form"
      },
      "source": [
        "#@title Original helpers.py module/functions\n",
        "# Useful Helper Functions that get called throughout all of our code\n",
        "# This includes data conversion, array concatenation, etc...\n",
        "\n",
        "# ----------------- Imports\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# For plotting\n",
        "import mido\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import mir_eval.display\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from mido import MidiFile\n",
        "\n",
        "\n",
        "from midi2audio import FluidSynth\n",
        "\n",
        "from google.colab import output, drive\n",
        "\n",
        "from IPython.display import display, Javascript, HTML, Audio, Image\n",
        "\n",
        "# ----------------- Helper Functions\n",
        "def hz_to_note_zeros(annotation):\n",
        "    '''\n",
        "        Special function so that zeros represent silence\n",
        "        Input: Annotation List taken straight from mtrack\n",
        "        Output: 1d np.array containing note names instead of frequencies\n",
        "    '''\n",
        "    new_values = np.array([])\n",
        "\n",
        "    for a in annotation:\n",
        "        new_a = '0'\n",
        "        if a != 0:\n",
        "            new_a = librosa.hz_to_note(a, cents=False)\n",
        "        new_values = np.append(new_values, new_a)\n",
        "\n",
        "    return new_values\n",
        "\n",
        "\n",
        "def note_to_hz_zeros(annotation):\n",
        "    '''\n",
        "        Special function so that zeros represent silence\n",
        "        Input: Annotation List taken straight from mtrack\n",
        "        Output: 1d np.array containing frequencies instead of note names\n",
        "    '''\n",
        "    new_values = np.array([])\n",
        "\n",
        "    for a in annotation:\n",
        "        new_a = 0\n",
        "        if a != '0':\n",
        "            new_a = librosa.note_to_hz(a)\n",
        "        new_values = np.append(new_values, new_a)\n",
        "\n",
        "    return new_values\n",
        "\n",
        "\n",
        "def midi_to_hz_zeros(annotation):\n",
        "    '''\n",
        "        Special function so that zeros represent silence\n",
        "        Input: Annotation List taken straight from mtrack\n",
        "        Output: 1d np.array containing frequencies instead of note names\n",
        "    '''\n",
        "    new_values = np.array([])\n",
        "\n",
        "    for a in annotation:\n",
        "        new_a = 0\n",
        "        if a != 0:\n",
        "            new_a = librosa.midi_to_hz(a)\n",
        "        new_values = np.append(new_values, new_a)\n",
        "\n",
        "    return new_values\n",
        "\n",
        "\n",
        "def hz_to_midi_zeros(annotation):\n",
        "    '''\n",
        "        Special function so that zeros represent silence\n",
        "        Input: Annotation List taken straight from mtrack\n",
        "        Output: 1d np.array containing frequencies instead of note names\n",
        "    '''\n",
        "    new_values = np.array([])\n",
        "\n",
        "    for a in annotation:\n",
        "        new_a = 0\n",
        "        if a != 0:\n",
        "            new_a = librosa.hz_to_midi(a)\n",
        "        new_values = np.append(new_values, new_a)\n",
        "\n",
        "    return new_values\n",
        "\n",
        "\n",
        "def note_to_midi_zeros(annotation):\n",
        "    '''\n",
        "        Special function so that zeros represent silence\n",
        "        Input: Annotation List taken straight from mtrack\n",
        "        Output: 1d np.array containing frequencies instead of note names\n",
        "    '''\n",
        "    new_values = np.array([])\n",
        "\n",
        "    for a in annotation:\n",
        "        new_a = 0\n",
        "        if a != '0':\n",
        "            new_a = librosa.note_to_midi(a)\n",
        "        new_values = np.append(new_values, new_a)\n",
        "\n",
        "    return new_values\n",
        "\n",
        "\n",
        "def midi_to_note_zeros(annotation):\n",
        "    '''\n",
        "        Special function so that zeros represent silence\n",
        "        Input: Annotation List taken straight from mtrack\n",
        "        Output: 1d np.array containing frequencies instead of note names\n",
        "    '''\n",
        "    new_values = np.array([])\n",
        "\n",
        "    for a in annotation:\n",
        "        new_a = '0'\n",
        "        if a != 0:\n",
        "            new_a = librosa.midi_to_note(a)\n",
        "        new_values = np.append(new_values, new_a)\n",
        "\n",
        "    return new_values\n",
        "\n",
        "\n",
        "def concat(data, feature_type):\n",
        "    '''\n",
        "    Concatenates all track information into one np.array to be used for model\n",
        "    Inputs:\n",
        "        List of dicts containing all song data\n",
        "        String representing the feature type to concatenate\n",
        "    Output: 1d or 2d np.array\n",
        "    '''\n",
        "    all_data = np.concatenate([d[feature_type] for d in data])\n",
        "    print(feature_type, 'array has shape: ', all_data.shape)\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def make_output_name(e, n, s):\n",
        "    '''\n",
        "        Creates a JSON output file name simply by concatenating the three\n",
        "        modes set by the user at the start of the program\n",
        "    '''\n",
        "    return 'results/' + 'predict_' + e + '_' + n + '_' + s + '.json'\n",
        "\n",
        "\n",
        "def count_pitches(annotation):\n",
        "    '''\n",
        "        Counts the unique classes in an annotation\n",
        "        Input: 1d np.array of either note or voicing annotations\n",
        "        Output: dict where class is the key and count is the value\n",
        "    '''\n",
        "    unique, counts = np.unique(annotation, return_counts=True)\n",
        "    pairs = np.asarray((unique, counts)).T  # 2d np.array\n",
        "    string_dict = dict(pairs.tolist())  # Converts counts to strings :(\n",
        "    int_dict = {k: int(v) for k, v in string_dict.items()}\n",
        "\n",
        "    return int_dict\n",
        "\n",
        "\n",
        "def common_pitches(data, threshold):\n",
        "    '''\n",
        "        Aggregates unique pitches across the entire inputted dataset\n",
        "        Inputs:\n",
        "            Dataset containing 'class_counts' field\n",
        "            Threshold value for to only include pitches above the line\n",
        "        Outputs:\n",
        "            Dict containing total counts based on each pitch\n",
        "            List containing all the pitches we plan to remove\n",
        "    '''\n",
        "    counts_list = [d['class_counts'] for d in data]\n",
        "    counter = Counter()\n",
        "\n",
        "    for d in counts_list:\n",
        "        counter.update(d)\n",
        "\n",
        "    all_counts = dict(counter)\n",
        "    to_remove = {k: v for k, v in counter.items() if v < threshold or k == '0'}\n",
        "\n",
        "    return to_remove, all_counts\n",
        "\n",
        "\n",
        "def keep_some_frames(track_dict, to_remove):\n",
        "    '''\n",
        "        Given a list of labels we do not want to train on, this function will\n",
        "        update the labels, features, and times lists to remove those frames\n",
        "        Inputs:\n",
        "            An audio track dict to be altered\n",
        "            A dict/list containing labels to wish to remove\n",
        "        Output: Modified dict\n",
        "    '''\n",
        "\n",
        "    lbls = track_dict['labels']\n",
        "    times = track_dict['times']\n",
        "    features = track_dict['features']\n",
        "\n",
        "    # Create a list of indices from labels to filter out\n",
        "    i_to_keep = [i for i, lbl in enumerate(lbls) if lbl not in to_remove]\n",
        "\n",
        "    # Then filter those values from times, labels, features\n",
        "    track_dict['labels'] = np.array([lbls[i] for i in i_to_keep])\n",
        "    track_dict['times'] = [times[i] for i in i_to_keep]  # Regular old list\n",
        "    track_dict['features'] = np.array([features[i] for i in i_to_keep])\n",
        "\n",
        "    return track_dict\n",
        "\n",
        "\n",
        "# TODO - Make the ordering of the input list stay constant\n",
        "def input_string(prompt_type, options_dict):\n",
        "    '''\n",
        "        Generates a string to print prompting for user input\n",
        "        Inputs:\n",
        "            String to indicate what the user is being asked for\n",
        "            Dict containing numbered options\n",
        "        Outputs:\n",
        "            String which will be printed to the console\n",
        "    '''\n",
        "    i_string = 'Please choose a(n) ' + prompt_type + ' mode: \\n'\n",
        "    for k, v in options_dict.items():\n",
        "        i_string += str(k) + ': ' + v + '\\n'\n",
        "    i_string += 'Your (integer) choice: '\n",
        "\n",
        "    return i_string\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGw2SHv21DZq",
        "cellView": "form"
      },
      "source": [
        "#@title Original exporter.py module/functions\n",
        "# Any exports done to memory contained in this file\n",
        "\n",
        "# ----------------- Imports\n",
        "import json\n",
        "#import helpers as hr\n",
        "import os\n",
        "\n",
        "\n",
        "# ----------------- Types of Data to Export\n",
        "def predictions(all_test_data, mode, file_name):\n",
        "    '''\n",
        "        Exports the predictions dict into a json file so that results\n",
        "        be loaded and graphed in another program\n",
        "        Inputs:\n",
        "            List of dicts containing all test results\n",
        "            String containing ['voicing' | 'melody' | 'all']\n",
        "        Outputs:\n",
        "            JSON File\n",
        "    '''\n",
        "    copy = []\n",
        "    for d in all_test_data:\n",
        "        new_d = {}\n",
        "        if mode != 'voicing':  # Convert Note Names to MIDI vals for plotting\n",
        "            new_d['labels'] = (note_to_midi_zeros(d['labels'])).tolist()\n",
        "            new_d['guesses'] = note_to_midi_zeros(d['guesses']).tolist()\n",
        "        else:\n",
        "            new_d['labels'] = d['labels'].tolist()\n",
        "            new_d['guesses'] = d['guesses'].tolist()\n",
        "\n",
        "        new_d['t_id'] = d['t_id']\n",
        "        new_d['times'] = d['times']\n",
        "        copy.append(new_d)\n",
        "\n",
        "    # Predictions written to a results directory, so make it if one does not\n",
        "    # yet exist\n",
        "    if not os.path.exists('results'):\n",
        "        os.makedirs('results')\n",
        "\n",
        "    with open(file_name, 'w') as file:\n",
        "        json.dump(copy, file)\n",
        "\n",
        "\n",
        "def train_test(train_test_data, train_test_name):\n",
        "    '''\n",
        "        Simply writes train/test split to a dictionary stored in melody\n",
        "        Inputs:\n",
        "            Dict containing the train/test split\n",
        "            Name to write the file as (Should be based on the task)\n",
        "        Output:\n",
        "            JSON File\n",
        "    '''\n",
        "    with open(train_test_name, 'w') as file:\n",
        "        json.dump(train_test_data, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu96STeuz-CG",
        "cellView": "form"
      },
      "source": [
        "#@title Original split.py module/functions\n",
        "# File used for generating or loading train/test splits\n",
        "# In practice, only final function should be used based on how the end user\n",
        "# has seleted to split up the data\n",
        "\n",
        "# ----------------- Imports\n",
        "\n",
        "import medleydb as mdb\n",
        "import os.path\n",
        "import json\n",
        "\n",
        "\n",
        "# ----------------- Global Variables\n",
        "train_test_split = 0.2  # Used for original dataset creation\n",
        "train_validate_split = 0.2  # Change if you would like new validation split\n",
        "train_test_name = 'train_test.json'\n",
        "\n",
        "\n",
        "# ----------------- Functions\n",
        "def quick_mode():\n",
        "    '''\n",
        "        Uses three short audio files for train and test data\n",
        "        Should be used for testing that the system runs all the way through\n",
        "        whithout crashing and not for estimating the strength of the features\n",
        "        Outputs:\n",
        "            List of medleydb tracks holding training data\n",
        "            List of medleydb tracks holding test data\n",
        "    '''\n",
        "    train = [mdb.MultiTrack('MusicDelta_Reggae'),\n",
        "             mdb.MultiTrack('MusicDelta_Rockabilly')]\n",
        "    test = [mdb.MultiTrack('MusicDelta_Shadows')]\n",
        "    return train, test\n",
        "\n",
        "\n",
        "def validation_mode():\n",
        "    '''\n",
        "        Creates a random split of the training data into train/test\n",
        "        Inputs:\n",
        "            Float ranging from 0 to 1 referring to how to split data up\n",
        "        Outputs:\n",
        "            train: List of multitrack objects to be used for training\n",
        "            test: List of multitrack objects to be used for validation\n",
        "    '''\n",
        "    # If we do not have a train/test set yet - create it!\n",
        "    if not os.path.isfile(train_test_name):\n",
        "        make_test_data()\n",
        "\n",
        "    with open(train_test_name, 'r') as file:\n",
        "        tt_data = json.load(file)\n",
        "\n",
        "    melody_ids = tt_data['train']  # Do nothing with test data\n",
        "    splits = mdb.utils.artist_conditional_split(trackid_list=melody_ids,\n",
        "                                                test_size=train_validate_split,\n",
        "                                                num_splits=1)\n",
        "\n",
        "    train = [mdb.MultiTrack(t_id) for t_id in splits[0]['train']]\n",
        "    test = [mdb.MultiTrack(t_id) for t_id in splits[0]['test']]\n",
        "    return train, test\n",
        "\n",
        "\n",
        "def test_mode():\n",
        "    '''\n",
        "        Loads the train_test data split from memory\n",
        "        Outputs:\n",
        "            train: List of multitrack objects to be used for training\n",
        "            test: List of multitrack objects to be used for testing\n",
        "    '''\n",
        "    if not os.path.isfile(train_test_name):\n",
        "        make_test_data()\n",
        "        print('Uh oh, you are starting to test before any validation?!')\n",
        "        print('Run again if you are really sure, but consider switching modes')\n",
        "        quit()\n",
        "\n",
        "    with open(train_test_name, 'r') as file:\n",
        "        tt_data = json.load(file)\n",
        "        train_ids = tt_data['train']  # Do nothing with test data\n",
        "        test_ids = tt_data['test']\n",
        "\n",
        "    train = [mdb.MultiTrack(t_id) for t_id in train_ids]\n",
        "    test = [mdb.MultiTrack(t_id) for t_id in test_ids]\n",
        "    return train, test\n",
        "\n",
        "\n",
        "def make_test_data():\n",
        "    '''\n",
        "        Creates one pair of data and exports: train/test\n",
        "        Should only be used once to generate train/test datasets at\n",
        "        the beginning of research\n",
        "        Outputs: JSON file called 'train_test.json'\n",
        "    '''\n",
        "    generator = mdb.load_melody_multitracks()\n",
        "    melody_ids = [mtrack.track_id for mtrack in generator]\n",
        "    splits = mdb.utils.artist_conditional_split(trackid_list=melody_ids,\n",
        "                                                test_size=train_test_split,\n",
        "                                                num_splits=1)\n",
        "\n",
        "    train, test = splits[0]['train'], splits[0]['test']\n",
        "\n",
        "    train_test_data = {'train': train, 'test': test}\n",
        "    train_test(train_test_data, train_test_name)\n",
        "\n",
        "    print('Generated Train/Test Data Split!')\n",
        "\n",
        "\n",
        "# ----------------- Function Generator\n",
        "def generate_split(split_type):\n",
        "    '''\n",
        "        Returns the right split function based on the string inputted\n",
        "        If the string 'options' is inputted, it will return a dict containing\n",
        "        modes rather than a function\n",
        "        Input: String containing ['options' | 'voicing' | 'melody' | 'all']\n",
        "        Output: Evaluation function corresponding to input\n",
        "    '''\n",
        "    splits_dict = {\n",
        "        'quick': quick_mode,\n",
        "        'validate': validation_mode,\n",
        "        'test': test_mode\n",
        "    }\n",
        "\n",
        "    if split_type == 'options':\n",
        "        return {i: k for i, k in enumerate(splits_dict)}\n",
        "    else:\n",
        "        return splits_dict[split_type]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijG3bHCN2vGE",
        "cellView": "form"
      },
      "source": [
        "#@title Original evaluate.py module/functions\n",
        "# File containing functions used for evaluation of all data\n",
        "# In practice, only the run_eval function should be used given a string\n",
        "# variable in the main function pertaining to the mode\n",
        "\n",
        "# Functions convert to cents and voicing following mirex guidlines:\n",
        "#    http://craffel.github.io/mir_eval/#module-mir_eval.melody\n",
        "\n",
        "# ----------------- Imports\n",
        "from mir_eval import melody as mel_eval\n",
        "import numpy as np\n",
        "\n",
        "# ----------------- Evaluation Functions\n",
        "def evaluate_model_voicing(test_guesses, test_labels):\n",
        "    '''\n",
        "        If we are only looking at voicing, then we only care about some metrics\n",
        "        Inputs:\n",
        "            1d Boolean np.array containing all predictions made by the model\n",
        "            1d Boolean np.array containing all ground truth labels\n",
        "        Output: Dict containing\n",
        "    '''\n",
        "    ref_voicing = test_labels.astype(bool)\n",
        "    est_voicing = test_guesses.astype(bool)\n",
        "\n",
        "    print('Evaluating voicing...')\n",
        "    vx_recall, vx_false_alarm = mel_eval.voicing_measures(ref_voicing,\n",
        "                                                          est_voicing)\n",
        "    print('Evaluating overall accuracy...')\n",
        "    correct_tries = (ref_voicing == est_voicing)\n",
        "    overall_accuracy = sum(correct_tries)/correct_tries.size\n",
        "\n",
        "    metrics = {\n",
        "        'vx_recall': vx_recall,\n",
        "        'vx_false_alarm ': vx_false_alarm,\n",
        "        'overall_accuracy': overall_accuracy\n",
        "    }\n",
        "\n",
        "    for m, v in metrics.items():  # Python2 is iteritems I think\n",
        "        print(m, ':', v)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def evaluate_model_melody(test_guesses, test_labels):\n",
        "    '''\n",
        "        Run standard pitch and chroma evaluations on all test data\n",
        "        Inputs:\n",
        "            1d np.array containing all predictions made by the model\n",
        "            1d np.array containing all ground truth labels\n",
        "        Outputs:\n",
        "            Dict holding results of all evaluations\n",
        "    '''\n",
        "    ref_freq = hr.note_to_hz_zeros(test_labels)\n",
        "    est_freq = hr.note_to_hz_zeros(test_guesses)\n",
        "\n",
        "    ref_cent = mel_eval.hz2cents(ref_freq)\n",
        "    est_cent = mel_eval.hz2cents(est_freq)\n",
        "\n",
        "    all_voiced = np.ones(len(ref_cent), dtype=bool)\n",
        "\n",
        "    print('Evaluating pitch...')\n",
        "    raw_pitch = mel_eval.raw_pitch_accuracy(all_voiced, ref_cent,\n",
        "                                            all_voiced, est_cent,\n",
        "                                            cent_tolerance=50)\n",
        "\n",
        "    print('Evaluating chroma...')\n",
        "    raw_chroma = mel_eval.raw_chroma_accuracy(all_voiced, ref_cent,\n",
        "                                              all_voiced, est_cent,\n",
        "                                              cent_tolerance=50)\n",
        "    metrics = {\n",
        "        'raw_pitch': raw_pitch,\n",
        "        'raw_chroma': raw_chroma,\n",
        "    }\n",
        "\n",
        "    for m, v in metrics.items():\n",
        "        print(m, ':', v)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def evaluate_model_all(test_guesses, test_labels):\n",
        "    '''\n",
        "        Run standard Mirex evaluations on all test data\n",
        "        Inputs:\n",
        "            1d np.array containing all predictions made by the model\n",
        "            1d np.array containing all ground truth labels\n",
        "        Outputs:\n",
        "            Dict holding results of all evaluations\n",
        "    '''\n",
        "    print('Running conversions...')\n",
        "    ref_freq = hr.note_to_hz_zeros(test_labels)  # And back to Hz!\n",
        "    est_freq = hr.note_to_hz_zeros(test_guesses)\n",
        "\n",
        "    ref_cent = mel_eval.hz2cents(ref_freq)  # Then to cents...\n",
        "    est_cent = mel_eval.hz2cents(est_freq)\n",
        "\n",
        "    ref_voicing = mel_eval.freq_to_voicing(ref_freq)[1]  # And voicings!\n",
        "    est_voicing = mel_eval.freq_to_voicing(est_freq)[1]\n",
        "\n",
        "    print('Evaluating voicing...')\n",
        "    vx_recall, vx_false_alarm = mel_eval.voicing_measures(ref_voicing,\n",
        "                                                          est_voicing)\n",
        "\n",
        "    print('Evaluating pitch...')\n",
        "    raw_pitch = mel_eval.raw_pitch_accuracy(ref_voicing, ref_cent,\n",
        "                                            est_voicing, est_cent,\n",
        "                                            cent_tolerance=50)\n",
        "\n",
        "    print('Evaluating chroma...')\n",
        "    raw_chroma = mel_eval.raw_chroma_accuracy(ref_voicing, ref_cent,\n",
        "                                              est_voicing, est_cent,\n",
        "                                              cent_tolerance=50)\n",
        "\n",
        "    print('Evaluating overall accuracy...')\n",
        "    overall_accuracy = mel_eval.overall_accuracy(ref_voicing, ref_cent,\n",
        "                                                 est_voicing, est_cent,\n",
        "                                                 cent_tolerance=50)\n",
        "\n",
        "    metrics = {\n",
        "        'vx_recall': vx_recall,\n",
        "        'vx_false_alarm ': vx_false_alarm,\n",
        "        'raw_pitch': raw_pitch,\n",
        "        'raw_chroma': raw_chroma,\n",
        "        'overall_accuracy': overall_accuracy\n",
        "    }\n",
        "\n",
        "    for m, v in metrics.items():  # Python2 is iteritems I think\n",
        "        print(m, ':', v)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ----------------- Function Generator\n",
        "def generate_eval(mode):\n",
        "    '''\n",
        "        Returns the right evaluation function based on the string inputted\n",
        "        Input: String containing ['options' | 'voicing' | 'melody' | 'all']\n",
        "        Output: Evaluation function corresponding to input\n",
        "    '''\n",
        "    evaluations = {\n",
        "        'voicing': evaluate_model_voicing,\n",
        "        'melody': evaluate_model_melody,\n",
        "        'all': evaluate_model_all\n",
        "    }\n",
        "\n",
        "    if mode == 'options':\n",
        "        return {i: k for i, k in enumerate(evaluations)}\n",
        "    else:\n",
        "        return evaluations[mode]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynuxpHac3Msm",
        "cellView": "form"
      },
      "source": [
        "#@title Original features.py module/functions\n",
        "# Possible Feature Representations to convert input audio\n",
        "# Style Note: Feature Representations meant to be called by user should begin\n",
        "# with 'with_' and should end with a call to 'final_steps'\n",
        "# Once a feature representation is ready, add it to the dict created in the\n",
        "# generator function and it will be accessible to the user\n",
        "\n",
        "# TODO - Figure out how to make final_steps a higher order function to\n",
        "# reduce code duplication for functions below that have the same steps (stft)\n",
        "\n",
        "# ----------------- Imports\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "from scipy.fftpack import fft\n",
        "from scipy.fftpack import ifft\n",
        "\n",
        "\n",
        "# ----------------- Global Variables\n",
        "target_sr = 22050  # Lower this if you decide to downsample\n",
        "original_sr = 44100  # Sampling rate for tracks in Medleydb\n",
        "n_fft = 1024\n",
        "win_length = 1024\n",
        "hop_length = int(256 * (target_sr / original_sr))  # So time points line up\n",
        "window = 'hann'\n",
        "\n",
        "\n",
        "# ----------------- Transformation Functions\n",
        "def with_stft(y):\n",
        "    '''\n",
        "        Runs a short-term Fourier transform\n",
        "        Input: Audio file\n",
        "        Output: 2d np.Array of size (time_points, num_features)\n",
        "    '''\n",
        "    s_array = librosa.stft(y, n_fft=n_fft, hop_length=hop_length,\n",
        "                           win_length=win_length, window=window)\n",
        "\n",
        "    abs_s = np.absolute(s_array)  # converts complex64 values to floats\n",
        "    return final_steps(abs_s)\n",
        "\n",
        "\n",
        "def with_cube_root(y):\n",
        "    '''\n",
        "        Takes the cube root of the STFT - supposed to model human hearing\n",
        "        Input: Audio file\n",
        "        Output: 2d np.Array of size (time_points, num_features)\n",
        "    '''\n",
        "    s_array = librosa.stft(y, n_fft=n_fft, hop_length=hop_length,\n",
        "                           win_length=win_length, window=window)\n",
        "\n",
        "    abs_s = np.absolute(s_array)\n",
        "    cbrt = np.cbrt(abs_s)\n",
        "    return final_steps(cbrt)\n",
        "\n",
        "\n",
        "def with_autocorrelation(y):\n",
        "    '''\n",
        "        Uses autocorrelation to detect periodic signals\n",
        "        Input: Audio file\n",
        "        Output: 2d np.Array of size (time_points, num_features)\n",
        "    '''\n",
        "    min_lag = 15\n",
        "    max_lag = 400\n",
        "\n",
        "    N_l = np.array(np.linspace((win_length)-min_lag,\n",
        "                   win_length-max_lag, max_lag-min_lag+1), ndmin=2)\n",
        "    N_l = np.transpose(N_l)\n",
        "    N_l = 1 / N_l\n",
        "\n",
        "    stft = stft_no_loss(y)\n",
        "\n",
        "    acf = np.zeros(stft.shape)\n",
        "    acf = acf + 0j\n",
        "    for i in range(stft.shape[1]):\n",
        "        acf[:, i] = ifft(np.power(np.absolute(stft[:, i]), 2))\n",
        "\n",
        "    acf = np.real(acf)\n",
        "\n",
        "    acf = acf[min_lag:max_lag+1, :]\n",
        "\n",
        "    acf = N_l * acf\n",
        "\n",
        "    return final_steps(acf)\n",
        "\n",
        "\n",
        "# TODO - We have determined that the entire frame contains all zeros\n",
        "# Figure out why this funcion is not working\n",
        "def with_cepstrum(y):\n",
        "    '''\n",
        "        Ceptstrum may be computed as the following:\n",
        "            FT -> abs() -> log() -> IFT -> real()\n",
        "        Input: Audio file\n",
        "        Output: 2d np.Array of size (time_points, num_features)\n",
        "    '''\n",
        "    stft = stft_no_loss(y)\n",
        "\n",
        "    abs_stft = np.absolute(stft)\n",
        "    abs_stft[abs_stft == 0] = 0.00001\n",
        "\n",
        "    log_stft = np.log(abs_stft)\n",
        "\n",
        "    i_log_stft = ifft(log_stft, axis=0)\n",
        "\n",
        "    cepstrum = np.real(i_log_stft)\n",
        "\n",
        "    return final_steps(cepstrum)\n",
        "\n",
        "\n",
        "def with_salience(y):\n",
        "    '''\n",
        "        Measurement of salience (percieved amplitude/energy) over time\n",
        "        Input: Audio file\n",
        "        Output: 2d np.Array of size (time_points, num_features)\n",
        "    '''\n",
        "    s_array = librosa.stft(y, n_fft=n_fft, hop_length=hop_length,\n",
        "                           win_length=win_length, window=window)\n",
        "    s_array = np.abs(s_array)\n",
        "    freqs = librosa.fft_frequencies(sr=target_sr, n_fft=n_fft)\n",
        "    h_range = [0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
        "\n",
        "    salience = librosa.salience(s_array, freqs, h_range)\n",
        "    salience[np.isnan(salience)] = 0\n",
        "\n",
        "    return final_steps(salience)\n",
        "\n",
        "\n",
        "def stft_no_loss(y):\n",
        "    '''\n",
        "        Unlike Librosa, this version of STFT does not remove any redundant\n",
        "        information\n",
        "        Input: Audio file\n",
        "        Output: 2d np.Array of size (num_features, time_points)\n",
        "    '''\n",
        "    stft = np.zeros((win_length, int(np.ceil(len(y)/hop_length)+1)))\n",
        "    stft = stft+0j\n",
        "\n",
        "    y = np.pad(y, int(n_fft / 2), mode='reflect')\n",
        "    stft_buffer = librosa.util.frame(y, frame_length=win_length,\n",
        "                                     hop_length=hop_length)\n",
        "\n",
        "    for i in range(stft_buffer.shape[1]):\n",
        "        stft[:, i] = fft(stft_buffer[:, i], n_fft)\n",
        "\n",
        "    return stft\n",
        "\n",
        "\n",
        "def final_steps(s):\n",
        "    '''\n",
        "    Wraps around normalize function and runs any final steps common\n",
        "    to all functions to finish processing a feature vector array\n",
        "    Input: 2d np.array\n",
        "    Output: Modified 2d np.array with range 0-1 and axes swapped\n",
        "    '''\n",
        "    # Normalize entire matrix from 0 to 1 - useful since amplitude differs\n",
        "    min_val = np.amin(s)\n",
        "    s = s - min_val\n",
        "    max_val = np.amax(s)\n",
        "    s = s / max_val\n",
        "\n",
        "    # Swap axes so that dimensions line up with annotation\n",
        "    return np.swapaxes(s, 0, 1)\n",
        "\n",
        "\n",
        "# ----------------- Function Generator\n",
        "def generate_transform(type):\n",
        "    '''\n",
        "        Returns the right transform function based on the string inputted\n",
        "        If the string 'options' is inputted, it will return a dict containing\n",
        "        modes rather than a function\n",
        "        Input: String transformation options or 'list'\n",
        "        Output: Either:\n",
        "            Transform function corresponding to input\n",
        "            Dict containing possible transformation functions for user input\n",
        "    '''\n",
        "    transformations = {\n",
        "        'stft': with_stft,\n",
        "        'cube_root': with_cube_root,\n",
        "        'autocorr': with_autocorrelation,\n",
        "        'cepstrum': with_cepstrum,\n",
        "        'salience': with_salience\n",
        "    }\n",
        "\n",
        "    if type == 'options':\n",
        "        return {i: k for i, k in enumerate(transformations)}\n",
        "    else:\n",
        "        return transformations[type]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZDxvb5ezqoW",
        "cellView": "form"
      },
      "source": [
        "#@title Original playground.py module/functions { run: \"auto\" }\n",
        "number_of_processing_threads = 4 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "evaluation_mode_selection = \"melody\" #@param [\"melody\", \"voicing\", \"all\"]\n",
        "feature_transformation_selection = \"stft\" #@param [\"stft\", \"cube_root\", \"autocorr\", \"cepstrum\", \"salience\"]\n",
        "split_train_val_test_selection = \"quick\" #@param [\"quick\", \"validate\", \"test\"]\n",
        "\n",
        "%cd /content/medleydb/\n",
        "\n",
        "# Willie Payne\n",
        "# Ana Elisa Mendez Mendez\n",
        "# Run Command: python3 playground.py\n",
        "\n",
        "# ----------------- Imports\n",
        "from multiprocessing import Pool  # For parallel processing\n",
        "\n",
        "import numpy as np  # For numerous calculations\n",
        "\n",
        "from sklearn import svm  # Machine learning algorithms\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import librosa  # Audio processing and data conversions\n",
        "from medleydb import *\n",
        "# Functions that we have written\n",
        "#import split  # For splitting train/validation/test\n",
        "#import features  # Feature transformation methods\n",
        "#import helpers as hr  # Useful helper functions\n",
        "#import exporter  # For exporting data to JSON\n",
        "#import evaluate  # Final step evaluation functions\n",
        "\n",
        "\n",
        "# ----------------- Global Variables\n",
        "num_processes = number_of_processing_threads  # Number of parallel processes for supported code blocks\n",
        "global e_mode  # Evaluation mode\n",
        "global n_mode  # Type of Feature transformation to use\n",
        "global s_mode  # Type of train/test/validate split to use\n",
        "e_mode = evaluation_mode_selection\n",
        "n_mode = feature_transformation_selection\n",
        "s_mode = split_train_val_test_selection\n",
        "\n",
        "# ----------------- Functions\n",
        "def get_started():\n",
        "    '''\n",
        "        Asks for user input for three categories: evaluation, feature, split.\n",
        "        This should be the first function ran since it sets the chain of events\n",
        "        by which the software follows.\n",
        "        Input: None\n",
        "        Output: None, Updates three global variables\n",
        "    '''\n",
        "    #global e_mode  # Only time global keyword is used since these should be\n",
        "    #global n_mode  # known across the entirety of the program\n",
        "    #global s_mode\n",
        "'''\n",
        "    e_options = generate_eval('options')\n",
        "    n_options = generate_transform('options')\n",
        "    s_options = generate_split('options')\n",
        "\n",
        "    e_choice = input(input_string('evaluation', e_options))\n",
        "    n_choice = input(input_string('feature', n_options))\n",
        "    s_choice = input(input_string('split', s_options))\n",
        "'''\n",
        "try:\n",
        "        #e_mode = e_options.get(int(e_choice), e_mode)\n",
        "        #n_mode = n_options.get(int(n_choice), n_mode)\n",
        "        #s_mode = s_options.get(int(s_choice), s_mode)\n",
        "        print('Ready! :)')\n",
        "except:\n",
        "        print('Oops, you must have typed something weird. Try running again.')\n",
        "        quit()\n",
        "\n",
        "\n",
        "def normalize_all(n_func, train_or_test):\n",
        "    '''\n",
        "        Iterates through all provided data and normalizes each mtrack\n",
        "        Inputs:\n",
        "            Function referring to the normalization function to run\n",
        "            List containing either training data or test data\n",
        "        Outputs: List of dicts\n",
        "    '''\n",
        "    func_with_data = [(n_func, mtrack) for mtrack in train_or_test]\n",
        "\n",
        "    with Pool(processes=num_processes) as pool:\n",
        "        feature_dict = pool.starmap(load_and_normalize, func_with_data)\n",
        "\n",
        "    return feature_dict\n",
        "\n",
        "\n",
        "def load_and_normalize(n_func, mtrack):\n",
        "    '''\n",
        "        Loads the selected audio file and runs normalization on it\n",
        "        Inputs:\n",
        "            Normalization function to use (begins with 'with_')\n",
        "            mtrack object from Medleydb\n",
        "        Output: Dict containing\n",
        "                    t_id: track id\n",
        "                    features: 2d np.array containing normalized feature vector\n",
        "                    labels: 1d np.array containing all labels\n",
        "                    times: list containing times for all annotations\n",
        "    '''\n",
        "    t_id = mtrack.track_id\n",
        "    y, sr = librosa.load(mtrack.mix_path, res_type='kaiser_fast',\n",
        "                         sr=target_sr, mono=True)  # or 'kaiser_best'\n",
        "\n",
        "    # Each annotation contains time stamp, and pitch value\n",
        "    times, annotation = zip(*mtrack.melody2_annotation)\n",
        "    annotation = list(annotation)\n",
        "    times = list(times)\n",
        "\n",
        "    normalized = n_func(y)  # Transform to feature representation\n",
        "\n",
        "    if len(normalized) != len(annotation):\n",
        "        if len(normalized) - len(annotation) == 1:\n",
        "            normalized = normalized[:-1]  # remove extra vector from end\n",
        "        elif len(annotation) - len(normalized) == 1:\n",
        "            annotation = annotation[:-1]\n",
        "            times = times[:-1]\n",
        "        else:  # Something really went wrong otherwise!\n",
        "            print('Error! Feature vector differs in length from labels.')\n",
        "            print(t_id, 'labels has size:', len(annotation))\n",
        "            print(t_id, 'features has size:', len(normalized))\n",
        "            quit()\n",
        "\n",
        "    if e_mode == 'voicing':\n",
        "        annotation = np.array([int(bool(v)) for v in annotation])\n",
        "    else:\n",
        "        annotation = hz_to_note_zeros(annotation)\n",
        "\n",
        "    # count unique pitches/voicings\n",
        "    class_counts = count_pitches(annotation)\n",
        "\n",
        "    print('Normalized', t_id, 'with', len(normalized), 'feature vectors')\n",
        "    return {'t_id': t_id, 'features': normalized,\n",
        "            'labels': annotation, 'times': times,\n",
        "            'class_counts': class_counts}\n",
        "\n",
        "\n",
        "def only_voiced_frames(data, to_remove=['0']):\n",
        "    '''\n",
        "        Mainly used by the melody mode classification to hold voiced frames\n",
        "        Inputs:\n",
        "            List of dicts containing all train or test data\n",
        "            List of pitches too rare to classify in addition to 0\n",
        "        Outputs:\n",
        "            Modified data list where undesirable frames/times/classes are\n",
        "            cut out\n",
        "    '''\n",
        "    arg_list = [(track, to_remove) for track in data]\n",
        "    with Pool(processes=num_processes) as pool:\n",
        "        updated_tracks = pool.starmap(keep_some_frames, arg_list)\n",
        "\n",
        "    return updated_tracks\n",
        "\n",
        "\n",
        "def train_model_svm(train_features, train_labels):\n",
        "    '''\n",
        "        Uses an SVM to train the melody prediction model\n",
        "        Inputs:\n",
        "            2d np.array containing all feature vectors for each time\n",
        "            1d np.array containing labels for all feature vectors*\n",
        "            * The length of both lists must be equal\n",
        "        Output: A classifier to be used for melody prediction\n",
        "    '''\n",
        "    clf = svm.SVC()\n",
        "    clf.fit(train_features, train_labels)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def train_model_forest(train_features, train_labels):\n",
        "    '''\n",
        "        Runs a Random Forest Classifier to train melody prediction model\n",
        "        Inputs:\n",
        "            2d np.array containing all feature vectors for each time\n",
        "            1d np.array containing labels for all feature vectors*\n",
        "            * The length of both lists must be equal\n",
        "        Output: A classifier to be used for melody prediction\n",
        "    '''\n",
        "    clf = RandomForestClassifier(max_depth=100, random_state=0,\n",
        "                                 n_jobs=num_processes)\n",
        "    clf.fit(train_features, train_labels)\n",
        "    return clf\n",
        "\n",
        "\n",
        "# TODO - Calculate accuracy per track to evaluate performance across genres\n",
        "def predict(clf, all_test_data):\n",
        "    '''\n",
        "        Run predictions on all tracks\n",
        "        Inputs:\n",
        "            Classifier created by train_model function\n",
        "            List of dicts containing\n",
        "        Output: Modified list of dicts containing 'guesses' field\n",
        "    '''\n",
        "    for track in all_test_data:\n",
        "        track['guesses'] = clf.predict(track['features'])\n",
        "\n",
        "    return all_test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhiOCiUOolgx"
      },
      "source": [
        "# Fix long path access:\n",
        "import ntpath\n",
        "ntpath.realpath = ntpath.abspath\n",
        "# Fix long path access."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8zKKyPA3euT",
        "cellView": "form"
      },
      "source": [
        "#@title RUN THE CODE with your selections\n",
        "import os\n",
        "os.chdir('/content/medleydb')\n",
        "get_started()  # Choose your weapon!\n",
        "\n",
        "e_func = generate_eval(e_mode)\n",
        "n_func = generate_transform(n_mode)\n",
        "s_func = generate_split(s_mode)\n",
        "\n",
        "print('You chose to evaluate', e_mode, 'training with', n_mode,\n",
        "      'using', s_mode, 'data')\n",
        "print('Here we go!')\n",
        "\n",
        "print('Splitting Train and Test Sets..........', end='')\n",
        "train, test = s_func()\n",
        "print('Done')\n",
        "\n",
        "print('Extracting Training Features..........')\n",
        "all_training_data = normalize_all(n_func, train)\n",
        "to_remove, train_counts = common_pitches(all_training_data, 50)\n",
        "print('Extracting Training Features..........Done')\n",
        "\n",
        "if e_mode == 'melody':\n",
        "    print('Removing Unvoiced Frames From Train..........', end='')\n",
        "    all_training_data = only_voiced_frames(all_training_data, to_remove)\n",
        "    print('Done')\n",
        "\n",
        "print('Concatenating all Feature Vectors..........')\n",
        "train_features = concat(all_training_data, 'features')\n",
        "train_labels = concat(all_training_data, 'labels')\n",
        "print('Concatenating all Feature Vectors..........Done')\n",
        "\n",
        "print('Training  Model..........', end='')\n",
        "clf = train_model_forest(train_features, train_labels)\n",
        "print('Done')\n",
        "\n",
        "print('Extracting Test Features..........')\n",
        "all_test_data = normalize_all(n_func, test)\n",
        "print('Extracting Test Features..........Done')\n",
        "\n",
        "if e_mode == 'melody':\n",
        "    print('Removing Unvoiced Frames From Test..........', end='')\n",
        "    all_test_data = only_voiced_frames(all_test_data)\n",
        "    print('Done')\n",
        "\n",
        "print('Making Predictions..........', end='')\n",
        "predictions = predict(clf, all_test_data)\n",
        "print('Done')\n",
        "\n",
        "print('Exporting Predictions..........')\n",
        "f_name = make_output_name(e_mode, n_mode, s_mode)\n",
        "exporter.predictions(all_test_data, e_mode, f_name)\n",
        "print('Done: Exported file as', f_name)\n",
        "\n",
        "print('Evaluating Results..........')\n",
        "test_guesses = concat(predictions, 'guesses')\n",
        "test_labels = concat(predictions, 'labels')\n",
        "e_func(test_guesses, test_labels)\n",
        "print('Evaluating Results..........Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYTJsKoO47oC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as ms\n",
        "import json\n",
        "\n",
        "with open('/content/train_test.json', 'r') as file:\n",
        "    predictions = json.load(file)\n",
        "\n",
        "print(predictions[0]['t_id'])\n",
        "print(type(predictions[0]['labels']), len(predictions[0]['labels']))\n",
        "print(type(predictions[0]['guesses']), len(predictions[0]['guesses']))\n",
        "print(type(predictions[0]['times']), len(predictions[0]['times']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}